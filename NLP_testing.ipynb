{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token \t\tLemma \t\tStopword\n",
      "--------------------------------------------------\n",
      "Tea\t\ttea\t\tFalse\n",
      "is\t\tbe\t\tTrue\n",
      "healthy\t\thealthy\t\tFalse\n",
      "and\t\tand\t\tTrue\n",
      "calming\t\tcalm\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tnot\t\tTrue\n",
      "you\t\t-PRON-\t\tTrue\n",
      "think\t\tthink\t\tFalse\n",
      "?\t\t?\t\tFalse\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(\"Tea is healthy and calming, don't you think?\")\n",
    "#tokens = [token for token in doc]\n",
    "#for token in doc:\n",
    "#    print(token)\n",
    "print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n",
    "print(\"-\"*50)\n",
    "for token in doc:\n",
    "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'healthy', 'tea', 'delicious', 'is', 'love', 'and', 'calming'} [1, 2, 0, 2, 1, 0, 0] [1, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "s1 = \"Tea is healthy. Tea is love.\"\n",
    "s2 = \"Tea is healthy, calming, and delicious.\"\n",
    "sentence1 = \"Tea is healthy. Tea is love.\".split()\n",
    "sentence2 = \"Tea is healthy, calming, and delicious.\".split()\n",
    "vocab = set([])\n",
    "vocs1 = []\n",
    "vocs2 = []\n",
    "for i in sentence1:\n",
    "    i = i.replace(\".\", \"\")\n",
    "    vocab.add(i.lower())\n",
    "for j in sentence2:\n",
    "    j = j.replace(\".\", \"\").replace(\",\", \"\")\n",
    "    vocab.add(j.lower())\n",
    "for i in vocab:\n",
    "    vocs1.append(s1.lower().count(i))\n",
    "    vocs2.append(s2.lower().count(i))\n",
    "print(vocab, vocs1, vocs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n",
      "TerminologyList Google Pixel\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "\n",
    "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
    "patterns = [nlp(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns)\n",
    "\n",
    "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
    "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
    "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\") \n",
    "matches = matcher(text_doc)\n",
    "print(matches)\n",
    "\n",
    "match_id, start, end = matches[-1]\n",
    "print(nlp.vocab.strings[match_id], text_doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
